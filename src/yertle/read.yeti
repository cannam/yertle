/*
    Yertle
    RDF/Turtle parser module

    Copyright (c) 2013-2014 Chris Cannam
    Copyright (c) 2013-2014 Queen Mary, University of London
  
    Permission is hereby granted, free of charge, to any person
    obtaining a copy of this software and associated documentation
    files (the "Software"), to deal in the Software without
    restriction, including without limitation the rights to use, copy,
    modify, merge, publish, distribute, sublicense, and/or sell copies
    of the Software, and to permit persons to whom the Software is
    furnished to do so, subject to the following conditions:

    The above copyright notice and this permission notice shall be
    included in all copies or substantial portions of the Software.

    THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
    EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
    MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
    NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS BE LIABLE FOR
    ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF
    CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION
    WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.

    Except as contained in this notice, the names of the Centre for
    Digital Music; Queen Mary, University of London; and Chris Cannam
    shall not be used in advertising or otherwise to promote the sale,
    use or other dealings in this Software without prior written
    authorization.
*/

module yertle.read;

/*
   Parser functions return Error "error text" | OK someValue, where
   someValue is itself a tagged variant type.

   The ~> operator defined in parsebits.yeti (evaluate the left side,
   pass result to the right side if it was OK something, or else
   return the error) is used extensively for control flow.

   Only namespace prefixes and partially constructed triples are
   returned as values from functions: when a triple is completed, it
   is "emitted" and added to the pending triples in the state object
   rather than being returned.  (This is necessary because there may
   be individual parse tokens that result in emitting more than one
   triple -- such as collection elements.)  Thus the top-level parse
   function (statement) returns only Error "error text" | OK (Empty
   ()) | End () (where End indicates end-of-file reached).
*/

char = load yertle.char;
store = load yertle.store;

load yertle.types;

load yertle.parsebits;
load yertle.ttlre; // Regex matchers for Turtle lexical elements
load yertle.blank;
load yertle.rdftypes;
load yertle.collection;

import java.lang: Character;
import java.io: StringReader, BufferedReader;

newLiteral string = { value = string, type = "", language = "" };

punctuation expected state =
    noseq state [whitespace, required expected];

havePunctuation expected state =
   (chomp state; state.reader.next == expected);

unicodeEscape state inIRI =
    required "\\" state ~>
      \(n = case state.reader.next of "u": 4; "U": 8; _: 0 esac;
        if n == 0 then Error "Expected \\U or \\u at \(state.reader.location)";
        else 
            state.reader.discard ();
            OK (Token (fold do a b: a ^ state.reader.read () done "" [1..n]));
        fi ~>
           \case of
            Token t:
                try
                    result = strJoin "" Character#toChars(number "0x\(t)");
                    if inIRI and not matchIRIChars result
                    then Error "Invalid escaped character \(result) in IRI at \(state.reader.location)";
                    else OK (Token result);
                    fi
                catch NumberFormatException _:
                    Error "Expected \(n)-character hex at \(state.reader.location)";
                catch IllegalArgumentException _:
                    Error "Escaped character out of range at \(state.reader.location)";
                yrt
            esac
        );

backslashEscapes = [
    't': "\t", 'b': "\b", 'n': "\n", 'r': "\r", 'f': "\f",
    '\': '\', '"': '"', "'": "'"
];

backslashEscape state = 
    required "\\" state ~>
      \(if state.reader.next in backslashEscapes then
            OK (Token backslashEscapes[state.reader.read ()]);
        else
            Error "Unknown escape sequence at \(state.reader.location)"
        fi);

percentEscape state =
    required "%" state ~>
      \(chars = state.reader.read () ^ state.reader.read ();
        try 
            OK (Token (strJoin "" Character#toChars(number "0x\(chars)")))
        catch NumberFormatException _:
            Error "Malformed percent escape '\(chars)' before \(state.reader.location)";
        yrt);

emit state triple =
    push state.pendingTriples triple;

emitWithSubject state subject polist =
   (for polist do po: emit state { s = subject, p = po.p, o = po.o } done;
    OK (Empty ()));

langtag state =
   (langtag' state = 
       (tag = state.reader.readMatch likeAZ;
        if state.reader.next == "-" then
            tag ^ state.reader.read () ^ langtag' state
        else
            tag
        fi);
    tokseq state [required "@", OK . Token . langtag']);

iriref state =
   (iriref' acc state =
       (part = state.reader.readMatch likeIRIPart;
        if state.reader.lookingAt likeSlashU then
            unicodeEscape state true ~>
               \case of
                Token u: iriref' (acc ^ part ^ u) state;
                esac;
        elif state.reader.next == "%" then
            percentEscape state ~>
               \case of
                Token p: iriref' (acc ^ part ^ p) state;
                esac;
        else
            OK (Token (acc ^ part));
        fi);
    tokseq state [required "<",
                  iriref' "",
                  required ">"]);

pnameCandidate state =
    // Read a thing that looks like a prefixed name. We don't test
    // here whether it's well-formed, the resulting text is checked
    // again by the caller depending on context.
   (pnameCandidate' acc r =
       (part = state.reader.readMatch likePNPart;
        n = r.next;
        if n == '.' and r.lookingAt likeDotInPN then
            pnameCandidate' (acc ^ part ^ r.read ()) r
        elif n == '\' then
            // We need to preserve the '\' here (instead of
            // unescaping) because only certain characters may be
            // escaped, and the caller tests that
            pnameCandidate' (acc ^ part ^ r.read () ^ r.read ()) r
        else
            OK (Token (acc ^ part))
        fi);
    pnameCandidate' "" state.reader);

pnameNS state =
    pnameCandidate state ~>
       \case of
        Token t:
            if strEnds? t ":" then
                pfx = strLeft t ((strLength t) - 1);
                if pfx == "" or matchPNPrefix pfx then
                    OK (Token pfx)
                else
                    Error "Malformed prefix '\(pfx)' at \(state.reader.location)"
                fi
            else
                Error "Expected ':' at end of prefix before \(state.reader.location)"
            fi
        esac;

//!!! This is not strictly how you expand IRIs relative to a base (see
//http://www.ietf.org/rfc/rfc3986.txt sec 5.2.2)
resolved state iri =
   (if strStarts? "#" iri then state.fileIri ^ iri
    elif matchAbsIRI iri then iri
    elif strStarts? "/" iri then state.baseIri ^ (strRight iri 1)
    else state.baseIri ^ iri
    fi as ~String)#intern();

withoutFile iri =
    if strEnds? iri "/" then iri
    else strLeft iri ((strLastIndexOf' iri "/") + 1)
    fi;

base state = 
    tokseq state [ whitespace, iriref ] ~>
       \case of
        Token iri: 
            state.baseIri := resolved state iri;
            state.fileIri := state.baseIri;
            OK (Empty ());
        esac;
                    
prefix state =
    tokseq state [ whitespace, pnameNS ] ~>
       \case of Token pname:
            tokseq state [ whitespace, iriref ] ~>
               \case of Token iri:
                   (res = resolved state iri;
                    state.prefixes[pname] := res;
                    OK (Prefix (pair pname res)));
                esac;
        esac;
       
sparqlBase state =
    pnameCandidate state ~>
       \case of Token t:
            if (strLower t) == "base" then base state;
            else Error "Expected BASE at \(state.reader.location)";
            fi
        esac;

sparqlPrefix state =
    pnameCandidate state ~>
       \case of Token t:
            if (strLower t) == "prefix" then prefix state;
            else Error "Expected PREFIX at \(state.reader.location)";
            fi
        esac;

directive state =
    case state.reader.next of
    "@": langtag state ~>
            \case of
             Token "prefix":
                 prefix state ~> do r: punctuation "." state ~> \(OK r) done;
             Token "base":
                 noseq state [ base, punctuation "." ];
             Token t: Error "Expected base or prefix, found '\(t)' at \(state.reader.location)";
             esac;
    "B": sparqlBase state;
    "b": sparqlBase state;
    "P": sparqlPrefix state;
    "p": sparqlPrefix state;
      _: Error "Expected @base, @prefix, BASE, or PREFIX at \(state.reader.location)";
    esac;

newBoolLiteral b =
    Literal (newLiteral (if b then "true" else "false" fi) with { type = booleanType });

// Assumes local is known to match the pname local escapes patterns
// (i.e. if it has any escapes, they will have enough characters in
// the escaped data)
unescapeLocal local =
   (unescapeLocal' acc local =
        if local == "" then acc
        elif strStarts? local "%" then
            hex = "0x\(strSlice local 1 3)";
            unescapeLocal' (acc ^ (strJoin "" Character#toChars(number hex)))
                (strRight local 3);
        elif strStarts? local "\\" then
            unescapeLocal' acc (strRight local 1);
        else
            var n = 0;
            len = strLength local;
            n < len and strChar local n != "%" and strChar local n != "\\"
                loop n := n + 1;
            if n == len then acc ^ local
            else unescapeLocal' (acc ^ strLeft local n) (strRight local n)
            fi;
        fi;
    unescapeLocal' "" local);

prefixExpanded state text =
    // Our splitPName regex doesn't test the prefix part for
    // well-formedness, because we immediately check whether the
    // prefix is known, and a malformed prefix must be unknown (we
    // tested for well-formedness when reading the namespaces). But it
    // does check the local part for well-formedness.
    case splitPName text of
    [M [_, prefix, local]]:
        if prefix in state.prefixes then
            try
                OK (IRI (resolved state
                            (state.prefixes[prefix] ^ unescapeLocal local)));
            catch NumberFormatException _:
                Error "Malformed escape in local name '\(local)' before \(state.reader.location)";
            yrt
        else
            Error "Unknown namespace prefix '\(prefix)' at \(state.reader.location)";
        fi;
    _: Error "Malformed prefixed name '\(text)' at \(state.reader.location)";
    esac;

prefixedName state =
    pnameCandidate state ~>
       \case of
        // We can't tell the difference, until we get here, between a
        // prefixed name and the bare literals true or false
        Token t:
            if t == "true" then OK (newBoolLiteral true);
            elif t == "false" then OK (newBoolLiteral false);
            else prefixExpanded state t;
            fi;
        esac;

aOrPrefixedName state =
    pnameCandidate state ~>
       \case of
        Token "a": OK rdfTypeIRI;
        Token t: prefixExpanded state t;
        esac;

blankNodeFor state b =
   (if not b in state.bnodeLabels then
        state.bnodeLabels[b] := newBlankNode ();
    fi;
    state.bnodeLabels[b]);

blank state =
    tokseq state [required '_', required ':', pnameCandidate] ~>
       \case of
        Token b:
            if matchBlank b then
                OK (blankNodeFor state b)
            else
                Error "Malformed blank node label '\(b)' at \(state.reader.location)";
            fi;
        esac;

// resolve cyclical dependency
// object -> nonLiteralObject -> collection -> object
// and
// object -> nonLiteralObject -> blankNodePropertyList -> objectList -> object
var object' state =
    Error "object' should have been reassigned";

// [15] collection ::= '(' object* ')'
collection state =
   (readObjects acc state =
        if havePunctuation ")" state then
            OK acc
        else
            object' state ~> do obj: readObjects (acc ++ [obj]) state done
        fi;
    required "(" state ~>
       \(readObjects [] state ~>
            do objects:
                if empty? objects then
                    required ")" state ~> \(OK rdfNilIRI);
                else
                    c = makeCollection objects;
                    for c (emit state);
                    required ")" state ~> \(OK (head c).s);
                fi
            done));

// [135s] iri ::= IRIREF | PrefixedName
iri state =
    case state.reader.next of
    "<": iriref state ~> \case of Token t: OK (IRI (resolved state t)); esac;
      _: prefixedName state;
    esac;

// [9] verb ::= predicate | 'a'
// where
// [11] predicate ::= iri
verb state =
    case state.reader.next of
    "<": iri state;
      _: aOrPrefixedName state;
    esac;

// [10] subject ::= iri | blank
subject state =
    case state.reader.next of
    "_": blank state;
    "(": collection state;
      _: iri state;
    esac ~>
       \case of
        Literal _: Error "Literal not permitted as subject at \(state.reader.location)";
        IRI iri: OK (IRI iri);
        Blank b: OK (Blank b);
        esac;

datatype state =
    required "^" state ~> \(required "^" state) ~> \(iri state);

// [133s] BooleanLiteral ::= 'true' | 'false'
booleanLiteral state =
   (lit = state.reader.readMatch likeAZLower;
    if lit == "true" then OK (newBoolLiteral true);
    elif lit == "false" then OK (newBoolLiteral false);
    else Error "Expected 'true' or 'false' at \(state.reader.location)";
    fi);

openQuote state =
   (r = state.reader;
    quote = r.next;
    if quote != "\"" and quote != "'" then
        Error "Expected quotation mark at \(state.reader.location)";
    else
        if (r.discard (); r.next == quote) then
            if (r.discard (); r.next == quote) then
                r.discard ();
                OK (Long quote); // three quotes: long string opening
            else
                OK (Empty ()); // two quotes: empty string
            fi
        else OK (Short quote); // one quote: short string opening
        fi
    fi);

longStringBody quote state =
   (longStringBody' params acc state =
       (text = acc ^ (state.reader.readMatch params.matcher);
        if state.reader.lookingAt likeSlashU then
            unicodeEscape state false ~>
               \case of
                Token t: longStringBody' params (text ^ t) state;
                esac
        elif state.reader.lookingAt likeStringEscape then
            backslashEscape state ~>
               \case of
                Token t: longStringBody' params (text ^ t) state;
                esac
        elif state.reader.next == params.qchar then
            if state.reader.lookingAt params.qlike then
                for [1..3] \(state.reader.discard ());
                OK (Token text);
            else
                longStringBody' params (text ^ state.reader.read ()) state
            fi
        elif state.reader.isEof then
            Error "End of file reached in long string"
        else
            longStringBody' params (text ^ state.reader.read ()) state
        fi);
    longStringBody' {
        qchar = quote,
        qlike = (like "^\(quote)\(quote)\(quote)"),
        matcher = if quote == "'" then likeStringSingle else likeStringDouble fi
    } "" state);

shortStringBody quote state =
   (matcher = if quote == "'" then likeStringSingle else likeStringDouble fi;
    shortStringBody' acc state =
       (text = state.reader.readMatch matcher;
        if state.reader.lookingAt likeSlashU then
            unicodeEscape state false ~>
               \case of
                Token t: shortStringBody' (acc ^ text ^ t) state;
                esac
        elif state.reader.lookingAt likeStringEscape then
            backslashEscape state ~>
               \case of
                Token t: shortStringBody' (acc ^ text ^ t) state;
                esac
        else 
            OK (Token (acc ^ text))
        fi);
    tokseq state [ shortStringBody' "", required quote ]);

stringBody state =
    openQuote state ~>
       \case of
        Empty ():
            OK (Token "");
        Short q:
            shortStringBody q state;
        Long q:
            longStringBody q state;
        esac;

rdfLiteral state =
    stringBody state ~>
       \case of
        Token t:
            case state.reader.next of
            "@": langtag state ~>
                   \case of Token lt:
                        OK (Literal (newLiteral t with { language = lt }));
                    esac;
            "^": datatype state ~>
                   \case of
                    IRI di:
                        OK (Literal (newLiteral t with { type = di }));
                    _: // e.g. boolean literal, or base/prefix
                        Error "Malformed datatype IRI at \(state.reader.location)";
                    esac;
              _: OK (Literal (newLiteral t));
            esac;
        esac;

numericCandidate state =
   (n = (state.reader.readMatch likeNumber ^
         if state.reader.lookingAt likeAfterDec then
             state.reader.discard ();
             "." ^ (state.reader.readMatch likeNumber)
         else ""
         fi);
    if (strEnds? n "e" or strEnds? n "E")
    then Error "Exponent missing at \(state.reader.location)"
    else OK (Token n)
    fi);

// Adapt the Turtle numeric literal syntax into something that Yeti's
// string to number conversion will like
parseableNumber n =
    if strStarts? n "+." then "0" ^ (strRight n 1)
    elif strStarts? n "+" then strRight n 1
    elif strStarts? n "." then "0" ^ n
    else n
    fi;

numericLiteral state =
    try
        numericCandidate state ~> 
           \case of
            Token n:
                type = if matchE n then doubleType
                       elif strIndexOf n "." 0 >= 0 then decimalType
                       else integerType
                       fi;
                // We aren't actually supposed to canonicalise numbers
                // when storing, it seems (judging from the spec
                // tests). Instead we should store them textually as
                // they appear in the file. However, we still convert
                // in order to test whether they are convertible
                do _: () done (number (parseableNumber n));
                OK (Literal (newLiteral "\(n)" with { type }));
            esac;
    catch NumberFormatException _:
        Error "Malformed numeric literal at \(state.reader.location)";
    catch IllegalArgumentException _: // happens if token is empty
        Error "Expected numeric literal at \(state.reader.location)";
    yrt;

// [13] literal ::= RDFLiteral | NumericLiteral | BooleanLiteral
literal state =
    case state.reader.next of
    "'": rdfLiteral state;
    '"': rdfLiteral state;   // "
    "t": booleanLiteral state;
    "f": booleanLiteral state;
      _: numericLiteral state;
    esac;

// resolve cyclical dependency
// blankNodePropertyList -> predicateObjectList -> objectList -> object -> nonLiteralObject -> blankNodePropertyList
var blankNodePropertyList' state = 
    Error "blankNodePropertyList' should have been reassigned";

nonLiteralObject state =
    case state.reader.next of
    "_": blank state;
    "(": collection state;
    "[": blankNodePropertyList' state;
      _: iri state;
    esac;

// [12] object ::= iri | blank | blankNodePropertyList | literal

object state =
    if matchNonLit state.reader.next then
        nonLiteralObject state;
    else
        literal state;
    fi;

object' := object;

// [8] objectList ::= object (',' object)*
//!!! not tail-recursive
objectList state =
   (chomp state;
    object state ~>
        do obj:
            if havePunctuation "," state then
               (state.reader.discard ();
                objectList state ~>
                   \case of Nodes nodes:
                        OK (Nodes (obj::nodes));
                    esac);
            else
                OK (Nodes [obj]);
            fi;
        done
    );

// [7] predicateObjectList ::= 	verb objectList (';' (verb objectList)?)*
// NB we permit an empty list here; caller must reject if its rule
// demands predicateObjectList rather than predicateObjectList?
predicateObjectList state =
   (predicateObjectList' acc state =
        if havePunctuation "." state or havePunctuation "]" state then
            OK (POList acc) // empty list, or ending with ; .
        else
            verb state ~>
               \case of
                IRI iri:
                    objectList state ~>
                       \case of Nodes nodes:
                            OK (POList (acc ++
                                        map do n: { p = IRI iri, o = n } done
                                            nodes));
                        esac;
                _: // e.g. boolean literal
                    Error "Expected IRI before \(state.reader.location)";
                esac ~>
                   \case of POList lst:
                        if havePunctuation ";" state then
                            havePunctuation ";" state loop state.reader.discard ();
                            predicateObjectList' lst state
                        else
                            OK (POList lst)
                        fi
                    esac;
        fi;
    predicateObjectList' [] state);

// blankNodePropertyList ::= '[' predicateObjectList ']'
blankNodePropertyList state =
    punctuation "[" state ~>
      \(predicateObjectList state ~>
           \case of POList polist:
               (bnode = newBlankNode ();
                emitWithSubject state bnode polist ~>
                   \(punctuation "]" state) ~>
                       \(OK bnode));
            esac;
        );

blankNodePropertyList' := blankNodePropertyList;

// [6] triples ::= subject predicateObjectList |
//                 blankNodePropertyList predicateObjectList?
//
// Handles the blankNodePropertyList part of that alternation
blankNodeTriples state = 
    blankNodePropertyList state ~> 
        do subj:
            predicateObjectList state ~>
               \case of POList polist:
                    emitWithSubject state subj polist;
                esac
        done;

// [6] triples ::= subject predicateObjectList |
//                 blankNodePropertyList predicateObjectList?
// 
// Handles the subject part of that alternation
subjectTriples state =
    subject state ~> 
        do subj:
            predicateObjectList state ~>
               \case of
                POList []:
                    Error "Predicate required after subject at \(state.reader.location)";
                POList polist:
                    emitWithSubject state subj polist;
                esac
        done;

triples state = 
    case state.reader.next of
    "[": blankNodeTriples state;
      _: subjectTriples state;
    esac;

// [2] statement ::= directive | triples '.'
statement state =
   (chomp state;
    if state.reader.isEof then End ()
    elif state.reader.next == "@" then
        directive state;
    elif state.reader.lookingAt likeSparqlBase or
         state.reader.lookingAt likeSparqlPfx then
        directive state;
    else
        triples state ~> \(punctuation "." state);
    fi);

document state =
   (document' pending state =
        case pending of
        triple::rest:
            triple :. \(document' rest state);
        _: 
            case statement state of
            OK (Empty ()):
               (triples = map Triple state.pendingTriples;
                clearArray state.pendingTriples;
                document' triples state);
            OK (Prefix p):
                (Prefix p) :. \(document' [] state);
            Error e:
               (state.reader.close ();
                [Error e]);
            End _:
               (state.reader.close ();
                []);
            esac
        esac;
    document' [] state);

newState reader fileIri =
    {
        reader,
        var fileIri = fileIri,
        var baseIri = withoutFile fileIri,
        pendingTriples = array [],
        prefixes = [:],
        bnodeLabels = [:],
    };

parse baseIri reader =
    document (newState reader baseIri);

/**
 * Parse the Turtle document with the given base IRI from the given
 * input handle. Return a lazy list of parsed triples.
 * 
 * Each returned list element is either a Prefix-tagged pair
 * containing namespace prefix and corresponding IRI, or a
 * Triple-tagged { s, p, o } structure containing a parsed triple
 * (with full IRIs, unabbreviated). If an error occurs during parsing,
 * the final element will be an Error-tagged string instead.
 */
parseTurtleHandle baseIri handle = 
    parse baseIri (char.reader handle);

/**
 * Parse the Turtle document with the given base IRI from the given
 * local file. Return a lazy list of parsed triples.
 * 
 * Each returned list element is either a Prefix-tagged pair
 * containing namespace prefix and corresponding IRI, or a
 * Triple-tagged { s, p, o } structure containing a parsed triple
 * (with full IRIs, unabbreviated). If an error occurs during parsing,
 * the final element will be an Error-tagged string instead.
 */
parseTurtleFile baseIri filename = 
    parseTurtleHandle baseIri (openInFile filename "UTF-8");

/**
 * Parse the Turtle document with the given base IRI found in the
 * given string.
 * 
 * Each returned list element is either a Prefix-tagged pair
 * containing namespace prefix and corresponding IRI, or a
 * Triple-tagged { s, p, o } structure containing a parsed triple
 * (with full IRIs, unabbreviated). If an error occurs during parsing,
 * the final element will be an Error-tagged string instead.
 */
parseTurtleString baseIri str =
    parseTurtleHandle baseIri
        (readerHandle (new BufferedReader(new StringReader(str))));

/**
 * Load into the store st a series of parsed triples and namespace
 * prefixes, in the format returned from the parse functions.
 */
loadParsedTriples st triples =
    fold
        do acc item:
            case acc of
            Error e: Error e;
            OK ():
                case item of
                Error e: Error e;
                Prefix { fst, snd }:
                //!!! should we add any prefix to store that is not derived from the file iri?
                    if /* fst == "" then OK () // Don't add empty prefix to store
                    elif */ st.havePrefix fst then OK () // Don't override
                    else OK (st.addPrefix fst snd) fi;
                Triple t:
                    OK (st.add t);
                esac
            esac   
        done
        (OK ())
        triples;

/**
 * Parse the Turtle document with the given base IRI from the given
 * local file, loading its triples and prefixes directly into the
 * store st.
 */
loadTurtleFile st baseIri filename =
    loadParsedTriples st (parseTurtleFile baseIri filename);

/**
 * Parse the Turtle document with the given base IRI from the given
 * local file, loading its triples and prefixes into a new store
 * created with store.newRdfStore().
 */
loadTurtleFileAsNewStore baseIri filename = 
   (st = store.newRdfStore ();
    loadParsedTriples st (parseTurtleFile baseIri filename) ~> \(Store st));

{
parseTurtleHandle is string -> input_handle -> list<parsed>, 
parseTurtleFile is string -> string -> list<parsed>, 
parseTurtleString is string -> string -> list<parsed>, 
loadParsedTriples is store_target -> list<parsed> -> Error string | OK (),
loadTurtleFile is store_target -> string -> string -> Error string | OK (),
loadTurtleFileAsNewStore is string -> string -> Error string | Store store,
}

